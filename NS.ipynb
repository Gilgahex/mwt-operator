{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from models.utils import train, test, LpLoss, get_filter, UnitGaussianNormalizer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_initializer(name):\n",
    "    \n",
    "    if name == 'xavier_normal':\n",
    "        init_ = partial(nn.init.xavier_normal_)\n",
    "    elif name == 'kaiming_uniform':\n",
    "        init_ = partial(nn.init.kaiming_uniform_)\n",
    "    elif name == 'kaiming_normal':\n",
    "        init_ = partial(nn.init.kaiming_normal_)\n",
    "    return init_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class sparseKernel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, alpha, c=1, \n",
    "                 nl = 1,\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernel,self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.conv = self.convBlock(alpha*k**2, alpha*k**2)\n",
    "        self.Lo = nn.Conv1d(alpha*k**2, c*k**2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, ich, Nx, Ny, T)\n",
    "        x = x.reshape(B, -1, Nx, Ny, T)\n",
    "        x = self.conv(x)\n",
    "        x = self.Lo(x.view(B, c*ich, -1)).view(B, c, ich, Nx, Ny, T)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    def convBlock(self, ich, och):\n",
    "        net = nn.Sequential(\n",
    "            nn.Conv3d(och, och, 3, 1, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return net \n",
    "    \n",
    "\n",
    "def compl_mul3d(a, b):\n",
    "    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "    op = partial(torch.einsum, \"bixyz,ioxyz->boxyz\")\n",
    "    return torch.stack([\n",
    "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
    "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
    "    ], dim=-1)\n",
    "\n",
    "\n",
    "# fft conv taken from: https://github.com/zongyi-li/fourier_neural_operator\n",
    "class sparseKernelFT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k, alpha, c=1, \n",
    "                 nl = 1,\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(sparseKernelFT, self).__init__()        \n",
    "        \n",
    "        self.modes = alpha\n",
    "\n",
    "        self.weights1 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, 2))\n",
    "        self.weights2 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, 2))        \n",
    "        self.weights3 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, 2))        \n",
    "        self.weights4 = nn.Parameter(torch.zeros(c*k**2, c*k**2, self.modes, self.modes, self.modes, 2))        \n",
    "        nn.init.xavier_normal_(self.weights1)\n",
    "        nn.init.xavier_normal_(self.weights2)\n",
    "        nn.init.xavier_normal_(self.weights3)\n",
    "        nn.init.xavier_normal_(self.weights4)\n",
    "        \n",
    "        self.Lo = nn.Conv1d(c*k**2, c*k**2, 1)\n",
    "#         self.Wo = nn.Conv1d(c*k**2, c*k**2, 1)\n",
    "        self.k = k\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, ich, N, N, T)\n",
    "        \n",
    "        x = x.reshape(B, -1, Nx, Ny, T)\n",
    "        x_fft = torch.rfft(x, 3, normalized=True, onesided=True)\n",
    "        \n",
    "        # Multiply relevant Fourier modes\n",
    "        l1 = min(self.modes, Nx//2+1)\n",
    "        l2 = min(self.modes, Ny//2+1)\n",
    "        out_ft = torch.zeros(B, c*ich, Nx, Ny, T//2 +1, 2, device=x.device)\n",
    "        \n",
    "        out_ft[:, :, :l1, :l2, :self.modes] = compl_mul3d(\n",
    "            x_fft[:, :, :l1, :l2, :self.modes], self.weights1[:, :, :l1, :l2, :])\n",
    "        out_ft[:, :, -l1:, :l2, :self.modes] = compl_mul3d(\n",
    "                x_fft[:, :, -l1:, :l2, :self.modes], self.weights2[:, :, :l1, :l2, :])\n",
    "        out_ft[:, :, :l1, -l2:, :self.modes] = compl_mul3d(\n",
    "                x_fft[:, :, :l1, -l2:, :self.modes], self.weights3[:, :, :l1, :l2, :])\n",
    "        out_ft[:, :, -l1:, -l2:, :self.modes] = compl_mul3d(\n",
    "                x_fft[:, :, -l1:, -l2:, :self.modes], self.weights4[:, :, :l1, :l2, :])\n",
    "        \n",
    "        #Return to physical space\n",
    "        x = torch.irfft(out_ft, 3, normalized=True, onesided=True, signal_sizes=(Nx, Ny, T))\n",
    "        \n",
    "        x = F.relu(x)\n",
    "        x = self.Lo(x.view(B, c*ich, -1)).view(B, c, ich, Nx, Ny, T)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "class MWT_CZ(nn.Module):\n",
    "    def __init__(self,\n",
    "                 k = 3, alpha = 5, \n",
    "                 L = 0, c = 1,\n",
    "                 base = 'legendre',\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(MWT_CZ, self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.L = L\n",
    "        H0, H1, G0, G1, PHI0, PHI1 = get_filter(base, k)\n",
    "        H0r = H0@PHI0\n",
    "        G0r = G0@PHI0\n",
    "        H1r = H1@PHI1\n",
    "        G1r = G1@PHI1\n",
    "        \n",
    "        H0r[np.abs(H0r)<1e-8]=0\n",
    "        H1r[np.abs(H1r)<1e-8]=0\n",
    "        G0r[np.abs(G0r)<1e-8]=0\n",
    "        G1r[np.abs(G1r)<1e-8]=0\n",
    "        \n",
    "        self.A = sparseKernelFT(k, alpha, c)\n",
    "        self.B = sparseKernelFT(k, alpha, c)\n",
    "        self.C = sparseKernelFT(k, alpha, c)\n",
    "        \n",
    "        self.T0 = nn.Conv1d(c*k**2, c*k**2, 1)\n",
    "\n",
    "        if initializer is not None:\n",
    "            self.reset_parameters(initializer)\n",
    "\n",
    "        self.register_buffer('ec_s', torch.Tensor(\n",
    "            np.concatenate((np.kron(H0, H0).T, \n",
    "                            np.kron(H0, H1).T,\n",
    "                            np.kron(H1, H0).T,\n",
    "                            np.kron(H1, H1).T,\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('ec_d', torch.Tensor(\n",
    "            np.concatenate((np.kron(G0, G0).T,\n",
    "                            np.kron(G0, G1).T,\n",
    "                            np.kron(G1, G0).T,\n",
    "                            np.kron(G1, G1).T,\n",
    "                           ), axis=0)))\n",
    "        \n",
    "        self.register_buffer('rc_ee', torch.Tensor(\n",
    "            np.concatenate((np.kron(H0r, H0r), \n",
    "                            np.kron(G0r, G0r),\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('rc_eo', torch.Tensor(\n",
    "            np.concatenate((np.kron(H0r, H1r), \n",
    "                            np.kron(G0r, G1r),\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('rc_oe', torch.Tensor(\n",
    "            np.concatenate((np.kron(H1r, H0r), \n",
    "                            np.kron(G1r, G0r),\n",
    "                           ), axis=0)))\n",
    "        self.register_buffer('rc_oo', torch.Tensor(\n",
    "            np.concatenate((np.kron(H1r, H1r), \n",
    "                            np.kron(G1r, G1r),\n",
    "                           ), axis=0)))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, k^2, Nx, Ny, T)\n",
    "        ns = math.floor(np.log2(Nx))\n",
    "\n",
    "        Ud = torch.jit.annotate(List[Tensor], [])\n",
    "        Us = torch.jit.annotate(List[Tensor], [])\n",
    "\n",
    "#         decompose\n",
    "        for i in range(ns-self.L):\n",
    "            d, x = self.wavelet_transform(x)\n",
    "            Ud += [self.A(d) + self.B(x)]\n",
    "            Us += [self.C(d)]\n",
    "        x = self.T0(x.reshape(B, c*ich, -1)).view(\n",
    "            B, c, ich, 2**self.L, 2**self.L, T) # coarsest scale transform\n",
    "\n",
    "#        reconstruct            \n",
    "        for i in range(ns-1-self.L,-1,-1):\n",
    "            x = x + Us[i]\n",
    "            x = torch.cat((x, Ud[i]), 2)\n",
    "            x = self.evenOdd(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def wavelet_transform(self, x):\n",
    "        xa = torch.cat([x[:, :, :, ::2 , ::2 , :], \n",
    "                        x[:, :, :, ::2 , 1::2, :], \n",
    "                        x[:, :, :, 1::2, ::2 , :], \n",
    "                        x[:, :, :, 1::2, 1::2, :]\n",
    "                       ], 2)\n",
    "        waveFil = partial(torch.einsum, 'bcixyt,io->bcoxyt') \n",
    "        d = waveFil(xa, self.ec_d)\n",
    "        s = waveFil(xa, self.ec_s)\n",
    "        return d, s\n",
    "        \n",
    "        \n",
    "    def evenOdd(self, x):\n",
    "        \n",
    "        B, c, ich, Nx, Ny, T = x.shape # (B, c, 2*k^2, Nx, Ny)\n",
    "        assert ich == 2*self.k**2\n",
    "        evOd = partial(torch.einsum, 'bcixyt,io->bcoxyt')\n",
    "        x_ee = evOd(x, self.rc_ee)\n",
    "        x_eo = evOd(x, self.rc_eo)\n",
    "        x_oe = evOd(x, self.rc_oe)\n",
    "        x_oo = evOd(x, self.rc_oo)\n",
    "        \n",
    "        x = torch.zeros(B, c, self.k**2, Nx*2, Ny*2, T,\n",
    "            device = x.device)\n",
    "        x[:, :, :, ::2 , ::2 , :] = x_ee\n",
    "        x[:, :, :, ::2 , 1::2, :] = x_eo\n",
    "        x[:, :, :, 1::2, ::2 , :] = x_oe\n",
    "        x[:, :, :, 1::2, 1::2, :] = x_oo\n",
    "        return x\n",
    "    \n",
    "    def reset_parameters(self, initializer):\n",
    "        initializer(self.T0.weight)\n",
    "    \n",
    "    \n",
    "class MWT(nn.Module):\n",
    "    def __init__(self,\n",
    "                 ich = 1, k = 3, alpha = 2, c = 1,\n",
    "                 nCZ = 3,\n",
    "                 L = 0,\n",
    "                 base = 'legendre',\n",
    "                 initializer = None,\n",
    "                 **kwargs):\n",
    "        super(MWT,self).__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.c = c\n",
    "        self.L = L\n",
    "        self.nCZ = nCZ\n",
    "        self.Lk = nn.Linear(ich, c*k**2)\n",
    "        \n",
    "        self.MWT_CZ = nn.ModuleList(\n",
    "            [MWT_CZ(k, alpha, L, c, base, \n",
    "            initializer) for _ in range(nCZ)]\n",
    "        )\n",
    "        self.BN = nn.ModuleList(\n",
    "            [nn.BatchNorm3d(c*k**2) for _ in range(nCZ)]\n",
    "        )\n",
    "        self.Lc0 = nn.Linear(c*k**2, 128)\n",
    "        self.Lc1 = nn.Linear(128, 1)\n",
    "        \n",
    "        if initializer is not None:\n",
    "            self.reset_parameters(initializer)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        B, Nx, Ny, T, ich = x.shape # (B, Nx, Ny, T, d)\n",
    "        ns = math.floor(np.log2(Nx))\n",
    "        x = model.Lk(x)\n",
    "        x = x.view(B, Nx, Ny, T, self.c, self.k**2)\n",
    "        x = x.permute(0, 4, 5, 1, 2, 3)\n",
    "    \n",
    "        for i in range(self.nCZ):\n",
    "            x = self.MWT_CZ[i](x)\n",
    "            x = self.BN[i](x.view(B, -1, Nx, Ny, T)).view(\n",
    "                B, self.c, self.k**2, Nx, Ny, T)\n",
    "            if i < self.nCZ-1:\n",
    "                x = F.relu(x)\n",
    "\n",
    "        x = x.view(B, -1, Nx, Ny, T) # collapse c and k**2\n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "        x = self.Lc0(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.Lc1(x)\n",
    "        return x.squeeze()\n",
    "    \n",
    "    def reset_parameters(self, initializer):\n",
    "        initializer(self.Lc0.weight)\n",
    "        initializer(self.Lc1.weight)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data_path = '../../data/ns_V1e-3_N5000_T50.mat'\n",
    "\n",
    "ntrain = 1000\n",
    "ntest = 200\n",
    "\n",
    "batch_size = 20"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "sub = 1\n",
    "S = 64 // sub\n",
    "T_in = 10\n",
    "T = 40\n",
    "\n",
    "dataloader = h5py.File(data_path)\n",
    "u_data = dataloader['u']\n",
    "t_data = dataloader['u']\n",
    "\n",
    "train_a = torch.from_numpy(u_data[:T_in, ::sub,::sub,:ntrain]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "train_u = torch.from_numpy(u_data[T_in:T_in+T, ::sub,::sub,:ntrain]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "\n",
    "test_a = torch.from_numpy(u_data[:T_in, ::sub,::sub,-ntest:]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "test_u = torch.from_numpy(u_data[T_in:T_in+T, ::sub,::sub,-ntest:]\n",
    "            ).permute(3, 1, 2, 0)\n",
    "\n",
    "print(train_u.shape)\n",
    "print(test_u.shape)\n",
    "assert (S == train_u.shape[-2])\n",
    "assert (T == train_u.shape[-1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1000, 64, 64, 40])\n",
      "torch.Size([200, 64, 64, 40])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "a_normalizer = UnitGaussianNormalizer(train_a)\n",
    "x_train = a_normalizer.encode(train_a)\n",
    "x_test = a_normalizer.encode(test_a)\n",
    "\n",
    "y_normalizer = UnitGaussianNormalizer(train_u)\n",
    "y_train = y_normalizer.encode(train_u)\n",
    "\n",
    "x_train = x_train.reshape(ntrain,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "x_test = x_test.reshape(ntest,S,S,1,T_in).repeat([1,1,1,T,1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# pad locations (x,y,t)\n",
    "gridx = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridx = gridx.reshape(1, S, 1, 1, 1).repeat([1, 1, S, T, 1])\n",
    "gridy = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridy = gridy.reshape(1, 1, S, 1, 1).repeat([1, S, 1, T, 1])\n",
    "gridt = torch.tensor(np.linspace(0, 1, T+1)[1:], dtype=torch.float)\n",
    "gridt = gridt.reshape(1, 1, 1, T, 1).repeat([1, S, S, 1, 1])\n",
    "\n",
    "x_train = torch.cat((gridx.repeat([ntrain,1,1,1,1]), gridy.repeat([ntrain,1,1,1,1]),\n",
    "                       gridt.repeat([ntrain,1,1,1,1]), x_train), dim=-1)\n",
    "x_test = torch.cat((gridx.repeat([ntest,1,1,1,1]), gridy.repeat([ntest,1,1,1,1]),\n",
    "                       gridt.repeat([ntest,1,1,1,1]), x_test), dim=-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, test_u), batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "ich = 13\n",
    "initializer = get_initializer('xavier_normal') # xavier_normal, kaiming_normal, kaiming_uniform\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "alpha = 12\n",
    "c = 4\n",
    "k = 3\n",
    "nCZ = 4\n",
    "L = 0\n",
    "model = MWT(ich, \n",
    "            alpha = alpha,\n",
    "            c = c,\n",
    "            k = k, \n",
    "            base = 'legendre', # chebyshev\n",
    "            nCZ = nCZ,\n",
    "            L = L,\n",
    "            initializer = initializer,\n",
    "            ).to(device)\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 500\n",
    "step_size = 100\n",
    "gamma = 0.5"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "myloss = LpLoss(size_average=False)\n",
    "y_normalizer.cuda()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_l2 = train(model, train_loader, optimizer, epoch, device,\n",
    "        lossFn = myloss, lr_schedule = scheduler,\n",
    "        post_proc = y_normalizer.decode)\n",
    "    \n",
    "    test_l2 = test(model, test_loader, device, lossFn=myloss, post_proc=y_normalizer.decode)\n",
    "    print(f'epoch: {epoch}, train l2 = {train_l2}, test l2 = {test_l2}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_RL",
   "language": "python",
   "name": "torch_rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}